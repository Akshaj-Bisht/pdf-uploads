# Operating Systems Exam Solutions

## Section A

### 1. (a) Mention names of any two mass storage devices. (1)
Hard Disk Drive (HDD) and Solid State Drive (SSD) are two common mass storage devices. Other examples include optical drives (CD/DVD/Blu-ray), magnetic tape drives, and USB flash drives.

### 1. (b) Differentiate between mv and cp commands in Unix/Linux. (2)
- **mv (move)**: Moves files or directories from one location to another. If used to move a file to the same directory with a different name, it effectively renames the file. The original file is removed from its source location.
- **cp (copy)**: Creates a duplicate of the specified file or directory. The original file remains intact at its source location, and a new copy is created at the target location.

### 1. (c) List two main functions of the Operating System. (2)
1. **Resource Management**: The OS manages computer hardware resources including CPU, memory, storage, and I/O devices, allocating them efficiently among competing processes.
2. **Process Management**: The OS creates, schedules, and terminates processes, providing an environment for applications to run.

Other key functions include memory management, file system management, and providing a user interface.

### 1. (d) What is a thread? What are the benefits of using threads in a programming environment? (1+1)
A thread is the smallest unit of execution within a process. It shares the process's resources including memory space and opened files, but has its own program counter, stack, and registers.

Benefits of using threads:
1. **Resource Efficiency**: Threads share the same address space, requiring less overhead than multiple processes
2. **Responsiveness**: Applications can remain responsive while performing background tasks
3. **Parallelism**: Threads can execute simultaneously on multi-core processors, improving performance
4. **Simplified Communication**: Threads can communicate more easily than separate processes since they share memory

### 1. (e) What is a two-level directory structure? (2)
A two-level directory structure organizes files into a hierarchy with two levels:
1. **Root Directory**: The top-level directory containing subdirectories
2. **User Directories**: The second level where individual users have their own directories

This structure solves the limitations of single-level directories by:
- Allowing files with the same name to exist in different directories
- Grouping files logically by user or project
- Providing better organization and search capabilities

### 1. (f) What is the difference between logical and physical address? (2)
- **Logical Address**: The address generated by the CPU during program execution. It's a virtual address that the program uses, independent of the actual physical memory location. Also called virtual address.
- **Physical Address**: The actual location in the physical memory (RAM) where data or instructions are stored. This is the address that is loaded into the memory address register of the processor.

The Memory Management Unit (MMU) translates logical addresses to physical addresses during execution.

### 1. (g) What is dual mode of operation in the context of an Operating System? (3)
Dual mode operation refers to the two distinct modes in which a CPU operates:

1. **User Mode**: 
   - Programs run with restricted privileges
   - Cannot directly access hardware or execute privileged instructions
   - Cannot modify system settings
   - Protection mechanisms are enforced

2. **Kernel Mode (Supervisor/System Mode)**:
   - Full access to hardware resources
   - Can execute privileged instructions
   - Can access any memory location
   - Used by the operating system kernel

This separation protects the system from malicious or faulty user programs. Transitions between modes occur through system calls, interrupts, and exceptions.

### 1. (h) Give an example for absolute path and relative path in a directory? (3)
**Absolute Path**:
- Specifies the complete path from the root directory
- Always begins with a forward slash (/)
- Example: `/home/user/documents/report.txt`

**Relative Path**:
- Specifies the location relative to the current working directory
- Does not begin with a forward slash
- Example: If you're in `/home/user/`, the relative path to the same file would be `documents/report.txt`

Special notations in relative paths:
- `.` refers to the current directory
- `..` refers to the parent directory
- Example: `../projects/code.c` refers to a file in a sibling directory of the current location

### 1. (i) Briefly describe the working of Shortest Remaining Time First scheduling algorithm. (3)
Shortest Remaining Time First (SRTF) is a preemptive version of Shortest Job First (SJF) scheduling algorithm:

1. The CPU is allocated to the process with the smallest remaining burst time
2. When a new process arrives, the remaining burst time of the current process is compared with the burst time of the newly arrived process
3. If the new process has a smaller burst time than the remaining time of the current process, the current process is preempted and the CPU is allocated to the new process
4. This continues until all processes are completed

Characteristics:
- Minimizes average waiting time
- Provides optimal average turnaround time
- Requires prediction of burst times
- May cause starvation for processes with longer burst times
- Has higher overhead due to frequent context switching

### 1. (j) What is meant by the term 'virtual address space' of a process? (2)
Virtual address space refers to the range of virtual memory addresses that an operating system makes available to a process. It's an abstraction that:

1. Provides each process with its own private address space, isolated from other processes
2. Allows programs to use contiguous memory addresses regardless of physical memory allocation
3. Enables processes to use more memory than physically available through techniques like paging and swapping
4. Maps a process's logical addresses to physical addresses through the MMU (Memory Management Unit)

The virtual address space includes code (text) segment, data segment, heap, and stack.

### 1. (k) List two system calls for each of the following: (2+2)
#### (i) Process control
1. **fork()**: Creates a new child process that is a duplicate of the parent process
2. **exec()**: Replaces the current process image with a new process image

Other examples: exit(), wait(), kill()

#### (ii) Device management
1. **open()**: Opens a file or device for reading or writing
2. **ioctl()**: Controls device-specific operations

Other examples: read(), write(), close()

### 1. (l) What is a Process Control Block (PCB)? Elaborate the information stored in it. (1+3)
A Process Control Block (PCB) is a data structure maintained by the operating system for each process. It contains all the information needed to manage a process.

Information stored in a PCB includes:

1. **Process Identification**:
   - Process ID (PID)
   - Parent process ID (PPID)
   - User ID

2. **Process State**:
   - New, ready, running, waiting, terminated

3. **CPU Registers**:
   - Program Counter
   - Stack Pointer
   - General-purpose registers
   - Status registers

4. **CPU Scheduling Information**:
   - Process priority
   - Scheduling queue pointers
   - Scheduling parameters

5. **Memory Management Information**:
   - Base and limit registers
   - Page tables or segment tables
   - Memory allocation information

6. **Accounting Information**:
   - CPU time used
   - Time limits
   - Account numbers

7. **I/O Status Information**:
   - List of open files
   - Allocated I/O devices

## Section B

### 2. (a) In a multiprogramming uniprocessor system, how many processes can be in running state and how many processes can be in ready state at a particular time? (2)
In a multiprogramming uniprocessor system:
- **Running State**: Only ONE process can be in the running state at any given time since there is only one CPU
- **Ready State**: Multiple processes can be in the ready state, waiting for their turn to execute on the CPU

The number of processes in the ready state is limited only by system resources like available memory.

### 2. (b) What is the challenge faced by the designers of Operating System while implementing Shortest Job First scheduling algorithm? (2)
The main challenges in implementing Shortest Job First (SJF) scheduling algorithm are:

1. **Burst Time Prediction**: It's difficult to accurately know the execution time of a process in advance. The OS must estimate burst times based on historical data or programmer-provided information.

2. **Starvation**: Long processes may never execute if shorter processes continuously arrive, leading to indefinite postponement (starvation) of longer jobs.

3. **Overhead**: Maintaining and updating burst time predictions adds system overhead.

4. **Arrival Time Complexity**: Handling processes that arrive at different times increases implementation complexity.

### 2. (c) A process goes through various states from its creation to termination. Illustrate the states of a process using a diagram and explain briefly the different states. (3+2)

[Note: A process state diagram would be drawn here showing New, Ready, Running, Waiting/Blocked, and Terminated states with arrows indicating transitions]

Process States:

1. **New/Created**: Process is being created and resources are being allocated
   
2. **Ready**: Process is loaded into main memory and waiting to be assigned to a processor
   
3. **Running**: Instructions are being executed by the CPU
   
4. **Waiting/Blocked**: Process is waiting for some event to occur (such as I/O completion)
   
5. **Terminated**: Process has finished execution, resources are being released

State Transitions:
- New → Ready: When the process is admitted by the system
- Ready → Running: When scheduler selects the process
- Running → Ready: When time quantum expires or higher priority process arrives
- Running → Waiting: When process requests I/O or waits for an event
- Waiting → Ready: When I/O completes or event occurs
- Running → Terminated: When process completes execution

### 3. (a) What is the Unix Kernel? (3)
The Unix Kernel is the core component of the Unix operating system that:

1. Acts as an interface between hardware and software applications
2. Manages system resources including CPU, memory, and I/O devices
3. Provides essential services like process management, memory management, file system management, and I/O management
4. Implements protection and security mechanisms
5. Operates in privileged (kernel) mode with direct access to hardware

The Unix kernel is monolithic, meaning it runs as a single large process in a single address space, though modern versions often support loadable kernel modules.

### 3. (b) What is the purpose of pipes in shell scripting? Give an example. (2)
Pipes in shell scripting allow the output of one command to be used as input to another command, creating a pipeline of operations. This enables complex operations through combinations of simple commands.

Purpose:
- Data transfer between processes
- Chaining commands for complex operations
- Filtering and transforming data

Example:
```
ls -l | grep "^d" | wc -l
```
This command counts the number of directories in the current location by:
1. Listing files in long format (`ls -l`)
2. Filtering for lines starting with 'd' which represent directories (`grep "^d"`)
3. Counting the number of lines in the output (`wc -l`)

### 3. (c) Write a shell script to input a number X and print all the prime numbers between 1 and N. The program should be well documented. (5)
```bash
#!/bin/bash

# Shell script to print all prime numbers between 1 and N
# Author: [Name]
# Date: May 17, 2025

# Check if an argument was provided
if [ $# -ne 1 ]; then
    echo "Usage: $0 <positive_integer>"
    exit 1
fi

# Store the input number
N=$1

# Validate that N is a positive integer
if ! [[ "$N" =~ ^[0-9]+$ ]] || [ $N -lt 1 ]; then
    echo "Error: Please enter a positive integer"
    exit 1
fi

echo "Prime numbers between 1 and $N are:"

# Function to check if a number is prime
is_prime() {
    local num=$1
    
    # 1 is not a prime number
    if [ $num -eq 1 ]; then
        return 1
    fi
    
    # 2 and 3 are prime
    if [ $num -eq 2 ] || [ $num -eq 3 ]; then
        return 0
    fi
    
    # Check if number is divisible by 2
    if [ $(($num % 2)) -eq 0 ]; then
        return 1
    fi
    
    # Check divisibility by odd numbers up to square root of num
    local sqrt=$(echo "sqrt($num)" | bc)
    for (( i=3; i<=sqrt; i+=2 )); do
        if [ $(($num % $i)) -eq 0 ]; then
            return 1
        fi
    done
    
    # If not divisible by any number, it's prime
    return 0
}

# Check each number and print if prime
for (( i=1; i<=N; i++ )); do
    if is_prime $i; then
        echo -n "$i "
    fi
done

echo # Print newline at the end
```

### 4. (a) A file named abc.txt contains following data: P1, P2, P3, P4, P5 at line 0. Draw Gantt Chart showing the execution of these processes using SJF (Shortest Job First). Calculate the avg. SJF turnaround time and average wait time. (3+3)

To solve this problem, we need information about the burst times of processes P1-P5, which doesn't appear to be completely provided in the image. However, I'll demonstrate how to solve an SJF scheduling problem with assumed burst times.

Assumed burst times:
P1: 6 units
P2: 2 units
P3: 8 units
P4: 3 units
P5: 4 units

In SJF, processes are executed in order of burst time (shortest first):
P2 → P4 → P5 → P1 → P3

Gantt Chart:
```
0      2      5      9     15     23
|--P2--|--P4--|--P5--|--P1--|--P3--|
```

Calculations:
- P2: CT=2, TAT=2, WT=0
- P4: CT=5, TAT=5, WT=2
- P5: CT=9, TAT=9, WT=5
- P1: CT=15, TAT=15, WT=9
- P3: CT=23, TAT=23, WT=15

Average Turnaround Time = (2+5+9+15+23)/5 = 54/5 = 10.8 units
Average Waiting Time = (0+2+5+9+15)/5 = 31/5 = 6.2 units

### 4. (b) What is the purpose of pipes in shell scripting? Give an example. (1+1)
[This question is repeated from 3(b), see answer above]

### 5. (a) A file named abc.txt contains following data: (2+2)
[This appears to be related to question 4(a), but the specific content isn't fully visible in the images]

### 5. (b) Give Unix/Linux commands to remove a file and remove a directory. (2)
To remove a file:
```
rm filename
```

To remove an empty directory:
```
rmdir directory_name
```

To remove a non-empty directory (recursively):
```
rm -r directory_name
```

### 5. (c) Each system call will require passing some parameters to the Operating System. What are the three methods to access data in a file? Give comparison in terms of efficiency and ease of implementation. (6)

The three methods to access data in a file are:

1. **Sequential Access**:
   - Data is accessed in sequential order, one record after another
   - Similar to reading a tape
   - Implementation: Simple read/write operations that proceed from the current position
   - Example system calls: read(), write()

2. **Direct Access (Random Access)**:
   - Records can be read or written in any order
   - Based on a disk model of a file with blocks/records of fixed size
   - Implementation: read_at_position(), write_at_position()
   - Example system calls: lseek() + read()/write()

3. **Indexed Access**:
   - Access records using an index like a key field
   - Implementation: Built on top of direct access with index structures
   - Example: Database management systems

Comparison:

| Access Method | Efficiency | Ease of Implementation |
|---------------|------------|------------------------|
| Sequential    | High for sequential operations, poor for random access | Easiest - simple implementation |
| Direct        | High for random operations on fixed-size records | Moderate - requires position calculations |
| Indexed       | Optimized for complex queries and searches | Most complex - requires index maintenance |

- Sequential access is most efficient for accessing all records or large portions in order
- Direct access is more efficient for specific record retrieval when position is known
- Indexed access provides the best balance for complex query patterns but has highest overhead

### 6. (a) What is an Application Programming Interface (API)? What are the advantages of a programming environment which uses API? (1+1)
An Application Programming Interface (API) is a set of rules, protocols, and tools that allows different software applications to communicate with each other. It defines the methods and data formats that applications can use to request and exchange information.

Advantages of using APIs:
1. **Abstraction**: Hides complex implementation details, allowing developers to focus on application logic
2. **Reusability**: Enables code reuse, reducing development time and effort
3. **Standardization**: Provides a consistent interface for interacting with services
4. **Modularity**: Promotes modular software design, making systems easier to maintain
5. **Interoperability**: Facilitates communication between different systems and platforms
6. **Security**: Provides controlled access to functionality and resources

### 6. (b) Explain the difference between system call and system program. (2)
**System Calls**:
- Low-level interfaces provided by the OS kernel
- Direct requests to the operating system for services
- Transition the processor from user mode to kernel mode
- Examples: open(), read(), write(), fork(), exec()

**System Programs**:
- Higher-level software that provide useful functions to users
- Often built on top of system calls
- Run in user mode (except when making system calls)
- Examples: compilers, file utilities, command shells, text editors

Key differences:
1. **Level of abstraction**: System calls are lower-level interfaces, while system programs are higher-level applications
2. **User interaction**: System calls are not directly invoked by users, while system programs are user-facing
3. **Implementation**: System calls are part of the OS kernel, while system programs run in user space
4. **Functionality**: System calls provide basic services, while system programs provide more complex functionality

### 6. (c) Each system call will require passing some parameters to the Operating System. What are the three parameter passing techniques? (3)
Three parameter passing techniques for system calls:

1. **Registers**:
   - Parameters are placed in CPU registers before the system call
   - Fast and simple for a small number of parameters
   - Limited by the number of available registers
   - Used for frequently called system calls with few parameters

2. **Memory-based (Block/Table)**:
   - Parameters are stored in a block or table in memory
   - The address of the block is passed in a register
   - Can handle many parameters of varying sizes
   - Slightly slower than using registers due to memory access

3. **Stack-based**:
   - Parameters are pushed onto the stack by the calling program
   - The OS pops parameters from the stack during the system call
   - Natural extension of function call mechanism
   - Good for languages with built-in stack management

### 6. (d) A memory has a page size of 1 KB, determine the page number and offset for the following addresses: (3×2)
#### (i) 3085
For address 3085:
- Page size = 1 KB = 1024 bytes
- Page number = 3085 ÷ 1024 = 3 (integer division)
- Offset = 3085 % 1024 = 13

#### (ii) 4205
For address 4205:
- Page size = 1 KB = 1024 bytes
- Page number = 4205 ÷ 1024 = 4 (integer division)
- Offset = 4205 % 1024 = 109

#### (iii) 6500
For address 6500:
- Page size = 1 KB = 1024 bytes
- Page number = 6500 ÷ 1024 = 6 (integer division)
- Offset = 6500 % 1024 = 356

### 7. (a) Draw a labelled diagram showing structure of a magnetic disk. (4)
[Note: A labeled diagram of a magnetic disk would be drawn here showing components like platters, read/write heads, tracks, sectors, cylinders, spindle, and actuator arm]

Main components of a magnetic disk:
1. **Platters**: Circular disks coated with magnetic material
2. **Spindle**: The axis around which platters rotate
3. **Read/Write Heads**: Components that read and write data on the platters
4. **Actuator Arm**: Moves the read/write heads across the platters
5. **Tracks**: Concentric circles on each platter surface
6. **Sectors**: Arc-shaped sections of tracks
7. **Cylinders**: The same track on all platters (vertically aligned)

### 7. (c) Given memory partition sizes of 200KB, 600KB, 100KB, 300KB and 450 KB. How would the processes of sizes 330KB, 250KB, 500KB and 350 KB be placed in the memory for first fit, best fit and worst fit algorithms. Calculate internal and external fragmentation in all three algorithms. (3×2+2)

Memory partitions: 200KB, 600KB, 100KB, 300KB, 450KB
Processes: 330KB, 250KB, 500KB, 350KB

#### First Fit Algorithm:
Places each process in the first available partition large enough to hold it.

1. Process 330KB → Partition 600KB (270KB internal fragmentation)
2. Process 250KB → Partition 450KB (200KB internal fragmentation)
3. Process 500KB → Cannot be allocated (no partition large enough)
4. Process 350KB → Cannot be allocated (no partition large enough)

Results:
- Internal Fragmentation: 270KB + 200KB = 470KB
- External Fragmentation: 200KB + 100KB + 300KB = 600KB (still not enough for remaining processes)

#### Best Fit Algorithm:
Places each process in the smallest partition large enough to hold it.

1. Process 330KB → Partition 450KB (120KB internal fragmentation)
2. Process 250KB → Partition 300KB (50KB internal fragmentation)
3. Process 500KB → Partition 600KB (100KB internal fragmentation)
4. Process 350KB → Cannot be allocated (no partition large enough)

Results:
- Internal Fragmentation: 120KB + 50KB + 100KB = 270KB
- External Fragmentation: 200KB + 100KB = 300KB

#### Worst Fit Algorithm:
Places each process in the largest partition large enough to hold it.

1. Process 330KB → Partition 600KB (270KB internal fragmentation)
2. Process 250KB → Partition 450KB (200KB internal fragmentation)
3. Process 500KB → Cannot be allocated (no partition large enough)
4. Process 350KB → Cannot be allocated (no partition large enough)

Results:
- Internal Fragmentation: 270KB + 200KB = 470KB
- External Fragmentation: 200KB + 100KB + 300KB = 600KB

### 6. (a) For a paging environment in the main memory, the logical address has two parts - page number and offset. The size of the page frame is 2K. What should be the size of the offset (in bits)? (3)
Given:
- Page frame size = 2K = 2048 bytes

To calculate the size of the offset in bits:
1. The offset must be able to address every byte within a page
2. For a page of 2048 bytes, we need log₂(2048) bits = log₂(2¹¹) = 11 bits

Therefore, the offset should be 11 bits in size.

With 11 bits, we can address 2¹¹ = 2048 different locations, which covers the entire page frame.

### 6. (b) What is preemptive and non-preemptive process scheduling? Name two algorithms for each and justify your categorization into preemptive and non-preemptive. (2+4)

**Preemptive Scheduling**:
- The CPU can be taken away from a process before it completes execution
- The OS can interrupt a running process to allocate the CPU to another process
- Decisions are made when a process arrives or when an interrupt occurs

Preemptive Algorithms:
1. **Round Robin (RR)**:
   - Each process gets a small time slice (quantum)
   - After the quantum expires, the process is preempted and moved to the back of the ready queue
   - Preemptive because a running process is forcibly removed from CPU after its time quantum

2. **Shortest Remaining Time First (SRTF)**:
   - Preemptive version of SJF
   - When a new process arrives, its burst time is compared with the remaining time of the current process
   - If new process has a shorter burst time, current process is preempted
   - Preemptive because a running process can be interrupted by a new process with shorter remaining time

**Non-preemptive Scheduling**:
- Once a process starts execution, it continues until it terminates or blocks for I/O
- The CPU is not taken away from a process while it is executing
- Decisions are made only when a process terminates or blocks

Non-preemptive Algorithms:
1. **First Come First Served (FCFS)**:
   - Processes are executed in the order they arrive
   - Non-preemptive because once a process gets the CPU, it keeps it until completion or I/O block
   - Simple but can lead to the convoy effect

2. **Shortest Job First (SJF)**:
   - Process with the shortest expected burst time is selected next
   - Non-preemptive because a running process is not interrupted even if a new process with shorter burst time arrives
   - Optimal for average waiting time but can cause starvation